<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>边缘检测 on Neal&#39;s Blog</title>
    <link>https://madneal.com/tags/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B/</link>
    <description>Recent content in 边缘检测 on Neal&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <copyright>© This post is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License，please give source if you wish to quote or reproduce.</copyright>
    <lastBuildDate>Sat, 18 Apr 2015 19:38:02 +0000</lastBuildDate>
    <atom:link href="https://madneal.com/tags/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CHEVP算法（CannyHough Estimation of Vanishing Points)</title>
      <link>https://madneal.com/post/chevp%E7%AE%97%E6%B3%95cannyhough-estimation-of-vanishing-points/</link>
      <pubDate>Sat, 18 Apr 2015 19:38:02 +0000</pubDate>
      <guid>https://madneal.com/post/chevp%E7%AE%97%E6%B3%95cannyhough-estimation-of-vanishing-points/</guid>
      <description>&lt;p&gt;这个算法是汪悦在 Lane detection and tracking using B-spline中提出来的。他在这篇论文中主要用的是B-spline模型，这个模型的主要优点是鲁棒性好，可以针对不同的情景进行处理，而且他将检测道路两边的边缘的问题转化成求解道路中间线的问题。&#xA;下面主要描述一下CHEVP算法：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;边缘像素提取&#xA;我们使用Canny边缘检测来获得边缘映射和边缘定位映射。选择方差σ = 1 并且模板的尺寸是9*1在X方向和Y方向上进行高斯卷积。边缘映射是通过一个合适的阈值处理得到的结果。在图表1中，图b是通过Canny边缘检测得到的边缘映射，图c则是边缘定位映射。&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20150418181001947&#34; alt=&#34;Canny边缘检测&#34;&gt;&lt;/li&gt;&#xA;&lt;li&gt;通过霍夫变化检测直线&#xA;检测到的边缘点将被用于对直线参数空间中可能的存在的线进行投票。图像被水平地分为几个部分，如图2a所示，为了适应因为道路弯曲从而导致道路消失点的变化。图像部分自下而上高度越来越小。每个图像分割部分都有它们自己的直线参数空间，每个图像分割部分中边缘点分别为可能的直线进行投票。通过对于规范化后的累加空间的阈值处理，直线分割最终能够在每一个图像分割部分中检测出来。&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20150418182703265&#34; alt=&#34;直线检测&#34;&gt;&lt;/li&gt;&#xA;&lt;li&gt;地平线和消失点检测&#xA;每一个图像分割部分中检测到的直线都是成对出现的，任意一队直线的相交部分会为另外一个霍夫空间中的消失点进行投票。投票的权重是根据最后一步产生的成对直线的规范化累加值决定的。这个过程在每个图像分割部分中分别重复，但是会在相同的霍夫空间中投票。&#xA;霍夫空间中对于每一列的投票会归总起来从来检测可能的消失点。获得投票最多的一行将会被选择座位地平线在图像平面中，如下图所示：&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20150418183150284&#34; alt=&#34;检测到的消失点&#34;&gt;&#xA;对于每个图像分割部分来说，它的消失点由地平线附近投票最多的点所决定。所有检测到的消失点可以再图4b中看到。注意一点，对于图像部分5，没有消失点存在，因为在这个图像分割部分并没有检测到直线。&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20150418183707651&#34; alt=&#34;(a)图像分割部分2的消失点(b)所有图像分割部分中检测到的消失点&#34;&gt;&lt;/li&gt;&#xA;&lt;li&gt;根据检测的道路线估计道路中间线的参数k&#xA;对于消失点进行投票的直线被认为是每个图像分割部分中道路线。从图像最下面的图像分割部分往上，挑选出在各个图像分割部分中的左右两边挑选出最接近去中间一列的检测到的道路线。如果这两条道路线在这个图像分割部分中并不存在，这个过程就会在更高的图像分割部分中进行，知道获得需要的道路线。图6表示两条直线L1和L2在图像分割部分4中，因为没有直线存在图像分割部分5中。&#xA;然后连接图像分割部分4中的消失点和P-l4和P-r4的中点P-m4（直线L1和直线L2的相交的部分）&#xA;参数k可以通过以下公式进行估计：&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20150418190012674&#34; alt=&#34;这里写图片描述&#34;&gt;&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20150418185932872&#34; alt=&#34;这里写图片描述&#34;&gt;&#xA;对于图7中中间线的估计的例子如下所示：&#xA;从图像分割部分4开始，因为图像分割部分5中不存在消失点，我们假设这个部分的消失点跟在分割部分4中的消失点。延伸通过vp4和P-m4交于图像分割部分5的P-m5点。同样的，我们在图像分割部分3中我们也能够检测到消失点。直线（vp3-P-m3)交于图像分割部分2的底部的P-m2处。同样的道理，适用于以上的部分&#xA;通过构建道路中间线，通过参数k和道路中间线我们可以估计处道路的两条边缘线，图8给出了例子&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20150418190952200&#34; alt=&#34;图5 作为道路特征选择的直线&#34;&gt;&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20150418191106768&#34; alt=&#34;图6&#34;&gt;&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20150418191144348&#34; alt=&#34;图7&#34;&gt;&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20150418191050568&#34; alt=&#34;图8&#34;&gt;&lt;/li&gt;&#xA;&lt;li&gt;计算道路模型的控制点来接近检测的道路中间线&#xA;可以利用很多方法来计算B-spline中的控制点通过中间线。因为B-spline后面的部分会准确地逼近道路边缘，这里我们只是粗略地使用B-spline来接近检测到的道路中间线。&#xA;我们是通过使用3个不同的控制点来构成两个部分的B-spline。为了让B-spline通过第一个和最后一个控制点，我们使用三倍的第一个和最后一个控制点。因此事实上一共有7个控制点，3个第一个控制点和3个最后一个控制点都是相同的。&#xA;我们首先选择P-m0和P-m5分别代表道路模型中的第一个控制点Q0和最后一个控制点Q2.节点P1的选择取决于图9中β1和β2的值。如果β1和β2的值不等于0，我们则选择P-m作为Q1。即P1=P-m，P-m是P-m1和P-m2的中点。如果β1为0，而β2不等于0.我们则选择P-m1作为P1(Q1).其他的情况，我们则选择P-m2作为P1(Q1).因此控制点Q1可以通过下面的公式计算：&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20150418192950119&#34; alt=&#34;这里写图片描述&#34;&gt;&#xA;![控制点初始化]&#xA;(&lt;a href=&#34;http://img.blog.csdn.net/20150418193033394)!%5B&#34;&gt;http://img.blog.csdn.net/20150418193033394)![&lt;/a&gt;道路模型初始化](&lt;a href=&#34;http://img.blog.csdn.net/20150418193239246&#34;&gt;http://img.blog.csdn.net/20150418193239246&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;实验结果&#34;&gt;实验结果##&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://img.blog.csdn.net/20150418193506058&#34; alt=&#34;阴影下的道路曲线&#34;&gt;&#xA;&lt;img src=&#34;http://img.blog.csdn.net/20150418193433213&#34; alt=&#34;相对直的道路线&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;引用：&#xA;Wang, Yue, Eam Khwang Teoh, and Dinggang Shen. &amp;ldquo;Lane detection and tracking using B-Snake.&amp;rdquo; Image and Vision computing 22.4 (2004): 269-280.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
