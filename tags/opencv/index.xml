<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Opencv on Neal&#39;s Blog</title>
    <link>https://madneal.com/tags/opencv/</link>
    <description>Recent content in Opencv on Neal&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en</language>
    <copyright>© This post is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License，please give source if you wish to quote or reproduce.</copyright>
    <lastBuildDate>Wed, 15 Apr 2015 12:08:20 +0000</lastBuildDate>
    <atom:link href="https://madneal.com/tags/opencv/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Iplimage versus Mat</title>
      <link>https://madneal.com/post/iplimage-versus-mat/</link>
      <pubDate>Wed, 15 Apr 2015 12:08:20 +0000</pubDate>
      <guid>https://madneal.com/post/iplimage-versus-mat/</guid>
      <description>&lt;p&gt;我们可能经常面临这样的困惑，Iplimage和Mat这两种数据结构，我们应该用哪一种数据结构。&#xA;Iplimage一开始就存在opencv库之中，他来源于Intel的另外一个函数库Intel Image Processing Library(IPL)，这是一种非常重要的数据结构。在经典书籍&lt;!-- raw HTML omitted --&gt;里面的sample用的基本都是Iplimage这个数据结构。但是这是一种C风格的数据结构，你必须为他分配以及释放内存。&#xA;Mat则是一种新的数据结构，越来越多的人也在使用这种数据结构了，因为它是面向对象的。所以我们不需要自己来为它管理内存。它是通过计数的方式来进行引用，如果它的引用计数为0的话，那么它就会自动释放内存。&#xA;老实说，用什么数据结构，我也不知道。因为我觉得有些方法，Mat数据结构还不具备，有的方法只有运用Iplimage才可以。&lt;/p&gt;&#xA;&lt;h2 id=&#34;将iplimage转化为mat&#34;&gt;将Iplimage转化为Mat&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;IplImage* ipl;&#xA;Mat m = cvarrToMat(ipl);&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>道路识别demo</title>
      <link>https://madneal.com/post/%E9%81%93%E8%B7%AF%E8%AF%86%E5%88%ABdemo/</link>
      <pubDate>Wed, 15 Apr 2015 09:55:48 +0000</pubDate>
      <guid>https://madneal.com/post/%E9%81%93%E8%B7%AF%E8%AF%86%E5%88%ABdemo/</guid>
      <description>&lt;p&gt;最近做的道路识别一开始终于弄懂了点东西，一开始在网上找到了一个简单的道路识别的opencvsharp的版本。我觉得opencvsharp真的是一个很好的东西，它封装了比opencv更多的数据结构和库，而且得益于.net平台的强大，使用起来也非常的便捷。唯一的缺点就是目前关于这方面的资料还是少之又少，后来我还是想一想把这个demo转换成cpp版本，也是一个非常简单的demo。&lt;/p&gt;&#xA;&lt;h2 id=&#34;opencvsharp版本&#34;&gt;opencvsharp版本&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;using System;&#xA;using System.Collections.Generic;&#xA;using System.Linq;&#xA;using System.Windows.Forms;&#xA;&#xA;using OpenCvSharp;&#xA;&#xA;namespace LaneDetection&#xA;{&#xA;    class Program&#xA;    {&#xA;        [STAThread]&#xA;        static void Main()&#xA;        {&#xA;            CvCapture cap = CvCapture.FromFile(&amp;#34;test1.mp4&amp;#34;);&#xA;            CvWindow w = new CvWindow(&amp;#34;Lane Detection&amp;#34;);&#xA;            CvWindow canny = new CvWindow(&amp;#34;Canny&amp;#34;);&#xA;            IplImage src, gray, dstCanny, halfFrame, smallImg;&#xA;            CvMemStorage storage = new CvMemStorage();&#xA;            CvSeq lines;&#xA;&#xA;            while (CvWindow.WaitKey(10) &amp;lt; 0)&#xA;            {&#xA;                src = cap.QueryFrame();&#xA;                halfFrame = new IplImage(new CvSize(src.Size.Width / 2, src.Size.Height / 2), BitDepth.U8, 3);&#xA;                Cv.PyrDown(src, halfFrame, CvFilter.Gaussian5x5);&#xA;&#xA;                gray = new IplImage(src.Size, BitDepth.U8, 1);&#xA;                dstCanny = new IplImage(src.Size, BitDepth.U8, 1);&#xA;                storage.Clear();&#xA;                &#xA;                // Crop off top half of image since we&amp;#39;re only interested in the lower portion of the video&#xA;                int halfWidth = src.Width / 2;&#xA;                int halfHeight = src.Height / 2;&#xA;                int startX = halfWidth - (halfWidth / 2);&#xA;                src.SetROI(new CvRect(0, halfHeight - 0, src.Width - 1, src.Height - 1));&#xA;&#xA;                gray.SetROI(src.GetROI());&#xA;                dstCanny.SetROI(src.GetROI());&#xA;&#xA;                src.CvtColor(gray, ColorConversion.BgrToGray);&#xA;                Cv.Smooth(gray, gray, SmoothType.Gaussian, 5, 5);&#xA;                Cv.Canny(gray, dstCanny, 50, 200, ApertureSize.Size3);&#xA;                canny.Image = dstCanny;&#xA;                storage.Clear();&#xA;                lines = dstCanny.HoughLines2(storage, HoughLinesMethod.Probabilistic, 1, Math.PI / 180, 50, 50, 100);&#xA;&#xA;                for (int i = 0; i &amp;lt; lines.Total; i++)&#xA;                {&#xA;                    CvLineSegmentPoint elem = lines.GetSeqElem&amp;lt;CvLineSegmentPoint&amp;gt;(i).Value;&#xA;                    &#xA;                    int dx = elem.P2.X - elem.P1.X;&#xA;                    int dy = elem.P2.Y - elem.P1.Y;&#xA;                    double angle = Math.Atan2(dy, dx) * 180 / Math.PI;&#xA;&#xA;                    if (Math.Abs(angle) &amp;lt;= 10)&#xA;                        continue;&#xA;&#xA;                    if (elem.P1.Y &amp;gt; elem.P2.Y + 50  || elem.P1.Y &amp;lt; elem.P2.Y -50 )&#xA;                    {&#xA;                        src.Line(elem.P1, elem.P2, CvColor.Red, 2, LineType.AntiAlias, 0);&#xA;                    }&#xA;                }&#xA;                src.ResetROI();&#xA;                storage.Clear();&#xA;                w.Image = src;&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;opencv版本&#34;&gt;opencv版本&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#include &amp;#34;stdafx.h&amp;#34;&#xA;#include &amp;lt;highgui.h&amp;gt;&#xA;#include &amp;lt;cv.h&amp;gt;&#xA;#include &amp;lt;math.h&amp;gt;&#xA;&#xA;using namespace cv;&#xA;using namespace std;&#xA;&#xA;#define INF 99999999&#xA;CvCapture* g_capture = NULL;&#xA;&#xA;int g_slider_pos = 0 ;&#xA;int frame_count = 0;&#xA;CvSeq* lines;&#xA;&#xA;&#xA;int main(int argc,char* argv[])&#xA;{                  &#xA;    cvNamedWindow( &amp;#34;show&amp;#34;);      &#xA;&#x9;g_capture=cvCreateFileCapture( &amp;#34;D:\\road.avi&amp;#34;);&#xA;    IplImage* frame;&#xA;    while(1)&#xA;    {  &#xA;&#x9;&#x9;CvMemStorage* storage = cvCreateMemStorage();&#xA;&#x9;&#x9;frame=cvQueryFrame(g_capture);&#xA;&#xA;&#x9;&#x9;//set the ROI of the original image&#xA;&#x9;&#x9;int x = 0,y = frame-&amp;gt;height/2;&#xA;&#x9;&#x9;int width = frame-&amp;gt;width,height = frame-&amp;gt;height/2;&#xA;&#xA;&#x9;&#x9;if(!frame) &#xA;&#x9;&#x9;&#x9;break; &#xA;&#xA;&#x9;&#x9;cvSetImageROI(frame,cvRect(x,y,width,height));&#xA;&#x9;&#x9;IplImage* gray = cvCreateImage(cvGetSize(frame),8,1);&#xA;&#x9;&#x9;cvCvtColor(frame,gray,CV_BGR2GRAY);&#xA;&#xA;&#x9;&#x9;cvCanny(gray,gray,50,100);&#xA;&#x9;&#x9;cvShowImage(&amp;#34;canny&amp;#34;,gray);&#xA;&#x9;&#x9;cvSmooth(gray,gray,CV_GAUSSIAN,3,1,0);&#xA;&#xA;&#x9;&#x9;//Hough&#xA;&#x9;&#x9;lines = cvHoughLines2(gray,storage,CV_HOUGH_PROBABILISTIC,1,CV_PI/180,50,90,50);&#xA;&#xA;&#x9;&#x9;//select approprivate lines acoording to the slope&#xA;&#x9;&#x9;for (int i = 0;i &amp;lt; lines-&amp;gt;total;i ++)&#xA;&#x9;&#x9;{&#xA;&#x9;&#x9;&#x9;double k =INF;&#xA;&#x9;&#x9;&#x9;CvPoint* line = (CvPoint*)cvGetSeqElem(lines,i);&#xA;&#x9;&#x9;&#x9;int dx = line[1].x - line[0].x;&#xA;&#x9;&#x9;&#x9;int dy = line[1].x - line[0].y;&#xA;&#x9;&#x9;&#x9;double angle = atan2(dy,dx) * 180 /CV_PI;&#xA;&#x9;&#x9;&#x9;if (abs(angle) &amp;lt;= 10)&#xA;&#x9;&#x9;&#x9;&#x9;continue;&#xA;&#x9;&#x9;&#x9;if (line[0].y &amp;gt; line[1].y + 50 || line[0].y &amp;lt; line[1].y - 50)&#xA;&#x9;&#x9;&#x9;{&#xA;&#x9;&#x9;&#x9;&#x9;cvLine(frame,line[0],line[1],CV_RGB(255,0,0),2,CV_AA);&#xA;&#x9;&#x9;&#x9;}&#xA;&#x9;&#x9;}&#xA;&#x9;&#x9;cvResetImageROI(frame);&#x9;&#x9;&#xA;&#x9;&#x9;cvShowImage( &amp;#34;show&amp;#34;,frame);&#xA;        char c = cvWaitKey(33);            &#xA;        if(c==27)&#xA;            break;&#xA;    } &#xA;&#x9;cvReleaseCapture(&amp;amp;g_capture);&#xA;&#x9;cvDestroyWindow( &amp;#34;show&amp;#34;);               &#xA;    return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;非常希望有弄这方面的人能和我讨论一下，若转载请注明出处，谢谢。&lt;/p&gt;</description>
    </item>
    <item>
      <title>opencv视频流的读取和处理</title>
      <link>https://madneal.com/post/opencv%E8%A7%86%E9%A2%91%E6%B5%81%E7%9A%84%E8%AF%BB%E5%8F%96%E5%92%8C%E5%A4%84%E7%90%86/</link>
      <pubDate>Sun, 12 Apr 2015 13:16:58 +0000</pubDate>
      <guid>https://madneal.com/post/opencv%E8%A7%86%E9%A2%91%E6%B5%81%E7%9A%84%E8%AF%BB%E5%8F%96%E5%92%8C%E5%A4%84%E7%90%86/</guid>
      <description>&lt;ol&gt;&#xA;&lt;li&gt;Opencv提供一个简单易用的框架以提取视频文件和USB摄像头中的图像帧，如果只是想读取某个视频，你只需要创建一个VideoCapture实例，然后在循环中提取每一帧。下面是一个简单的代码&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;#include&amp;lt;opencv2\core\core.hpp&amp;gt;&#xA;#include&amp;lt;opencv2\imgproc\imgproc.hpp&amp;gt;&#xA;#include&amp;lt;opencv2\highgui\highgui.hpp&amp;gt;&#xA;#include&amp;lt;iostream&amp;gt;&#xA;using namespace cv;&#xA;using namespace std;&#xA;&#xA;int main()&#xA;{&#xA;&#x9;VideoCapture capture(&amp;#34;d:\\road.avi&amp;#34;);&#xA;&#x9;//检测视频是否读取成功&#xA;&#x9;if (!capture.isOpened())&#xA;&#x9;{&#xA;&#x9;&#x9;cout &amp;lt;&amp;lt; &amp;#34;No input image&amp;#34;;&#xA;&#x9;&#x9;return 1;&#xA;&#x9;}&#xA;&#xA;&#x9;//获取图像帧率&#xA;&#x9;double rate = capture.get(CV_CAP_PROP_FPS);&#xA;&#x9;bool stop = false;&#xA;&#x9;Mat frame;&#xA;&#x9;namedWindow(&amp;#34;Example&amp;#34;);&#xA;&#xA;&#x9;int delay = 1000/rate;&#xA;&#xA;&#x9;while (!stop)&#xA;&#x9;{&#xA;&#x9;&#x9;if (!capture.read(frame))&#xA;&#x9;&#x9;&#x9;break;&#xA;&#x9;&#x9;imshow(&amp;#34;Example&amp;#34;,frame);&#xA;&#x9;&#x9;if (waitKey(delay) &amp;gt;= 0)&#xA;&#x9;&#x9;&#x9;stop = true;&#xA;&#x9;}&#xA;&#x9;return 0;&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;要正确地打开视频文件必须确保电脑具有相应的解码器。同时也应该注意文件路径的未知是否正确，路径为止错误经常也会提示错误warning: Error opening file (../../modules/highgui/src/cap_ffmpeg_impl.hpp:545)。这个错误一般都是文件路径错误而导致的。&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;处理视频帧&#xA;为了对视频中的每一帧进行处理，我们可以创建自己的类VideoProcessor,其中封装OopenCV的视频获取框架，该类允许我们制定每帧调用的处理函数。&#xA;首先，我们希望制定一个回调处理函数，（关于回调函数，另外一个帖子http://blog.csdn.net/neal1991/article/details/45009377有介绍）。这个喊出可以接受一个Mat对象然后输出处理之后的Mat对象。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;void processFrame(Mat&amp;amp; img, Mat&amp;amp; out);&#xA;&#xA;&#xA;    // 对视频的每帧做Canny算子边缘检测&#xA;void canny(Mat&amp;amp; img, Mat&amp;amp; out) &#xA;{&#xA;    // 先要把每帧图像转化为灰度图&#xA;   cvtColor(img,out,CV_BGR2GRAY);&#xA;    // 调用Canny函数&#xA;   Canny(out,out,100,200);&#xA;    // 对像素进行翻转&#xA;    threshold(out,out,128,255,THRESH_BINARY_INV);&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;定义好一个视频处理类，它将与一个回调函数相关联。使用该类，可以创建一个实例，制定输入的视频文件，绑定回调函数，然后开始对每一帧进行处理，要调用这个视频处理类，只需要在main函数添加就可以了：&lt;/p&gt;</description>
    </item>
    <item>
      <title>OPENCV</title>
      <link>https://madneal.com/post/opencv/</link>
      <pubDate>Sat, 11 Apr 2015 11:22:35 +0000</pubDate>
      <guid>https://madneal.com/post/opencv/</guid>
      <description>&lt;p&gt;[转载]&#xA;&lt;a href=&#34;http://blog.csdn.net/carson2005/article/details/6979806&#34;&gt;http://blog.csdn.net/carson2005/article/details/6979806&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;尽管之前写过一篇关于OpenCV的介绍（http://blog.csdn.net/carson2005/article/details/5822149），但依然有朋友对其不甚了解。所以，经常能碰到有人问我诸如以下一些问题：OpenCV能不能实现人脸识别？OpenCV有没有车辆检测的API？OpenCV有没有三维重建的函数？面对这样的问题，我也很困惑。到底该如何给他们解释，才能让它们明白，OpenCV确实很强大，但还没有他们想象中的那么强大。其实，OpenCV的全称，是Open source Computer Vision Library,开放源代码计算机视觉库。也就是说，它是一套关于计算机视觉的开放源代码的API函数库。这也就意味着，(1)不管是科学研究，还是商业应用，都可以利用它来作开发;(2)所有API函数的源代码都是公开的，你可以看到其内部实现的程序步骤；(3)你可以修改OpenCV的源代码，编译生成你需要的特定API函数。但是，作为一个库，它所提供的，仅仅是一些常用的，经典的，大众化的算法的API。一个典型的计算机视觉算法，应该包含以下一些步骤：(1)数据获取（对OpenCV来说，就是图片）；(2)预处理;(3)特征提取;(4)特征选择;(5)分类器设计与训练;(6)分类判别;而OpenCV对这六个部分，分别（记住这个词）提供了API。下面我分别就这六个部分对一些常见问题进行必要的解释。&#xA;对于数据获取，计算机视觉领域的数据，无非就是图片和视频两种。图片，有bmp,jpg,png,tiff&amp;hellip;.各种压缩和非压缩格式。所以，对压缩格式的图片而言，OpenCV内部必然包含了对应的图片解压缩函数(一般都是包含了开源的图片解压函数库，例如，对于jpg压缩格式而言，就包含了libjpg开源库)。而对于视频而言，常见的有.rmvb,.avi,.asf等格式，不同的格式，代表着不同的视频压缩算法(对于AVI格式，尽管都是avi格式，但内部的压缩算法仍然不相同。具体原因请参考我的另一篇博客:http://blog.csdn.net/carson2005/article/details/6314089)，也就需要对应的解压算法来解压。尽管OpenCV提供了一些读写视频文件的API，但是，它也仅仅是一个接口而已，其内部，依然需要调用相应的视频编解码器的API来进行解码。常用的视频编解码器有：xvid,ffmpeg等。也就是说，如果你想利用OpenCV来进行视频读写之类的操作，是需要安装此类视频编解码器的。安装了相应的视频解码器之后，你就可以调用OpenCV的视频相关API来进行视频文件的读取操作了，当然，视频文件被解码之后，变成了一张一张的图片，然后才能被OpenCV所处理。另外，还有一种情况，就是数据来自于相机，包括数字相机和模拟相机。不管是哪种相机，你都要想办法获取到相机发送给PC的图片数据（PC在内存里面接收到的来自相机的数据可能是jpg格式，也可能是bmp格式）。如果，你在PC内存中接收到的是相机发送过来的jpg压缩格式，还需要进行图片数据的内存解压。关于相机和OpenCV的这部分内容，请见我另一篇博客：&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/carson2005/article/details/6243476&#34;&gt;http://blog.csdn.net/carson2005/article/details/6243476&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;对于预处理，一般就是去除或者降低噪声，光照归一化，亮度归一化，模糊化，锐化，膨胀，腐蚀、开闭等这些操作（详见，冈萨雷斯，《数字图像处理》一书）。而对于这些操作，OpenCV分别(又提到这个词了)提供了相应API函数。而光照的预处理，OpenCV提供了一个直方图均衡化的API，后续可能会提供一些gammar矫正之类的函数。&lt;/p&gt;&#xA;&lt;p&gt;对于特征提取，个人认为，可以算是整个计算机视觉系统中最为复杂也最难的部分（纯属个人意见，如有异议，请保留），到底什么是特征，该如何来理解这个看似简单却又包罗万象的名词呢？其实，要想仔细解释，还真的花费很多时间（有兴趣的可以看看，Richard O.Duda（著），李宏东（译），《模式识别》，机械工业出版社）。简单点说，特征，就是一个可以将若干个类别可以尽量分开的一种描述。举例来说，如果你要进行男人和女人的分类，显然，用“身高和体重”这一描述来衡量，是可以的，但是，这两个描述没有“胸部大小”这一描述更加准确，而“胸部大小”这一描述，又没有“喉结的有无”这一描述更准确。很显然，“身高和体重”，“胸部大小”，“喉结的有无”，这三种描述，都可以用来进行男人和女人的分类，只不过，它们对事物的描述的准确（或者说全面）程度是不同的，而诸如此类的描述，有一个更加专业的称谓，叫做“特征”。OpenCV里面，提供了一些特征描述的API，比如，对于人脸检测而言，它提供了haar特征的API，行人检测，提供了hog特征的API，甚至，它提供了LBP纹理特征的API。但是，这些还远远不够。例如，如果你要进行字符识别，OpenCV并没有提供字符识别所对应的特征。这个时候，就需要你自己来编程实现了。当然，该选择什么特征来描述字符呢？哪些特征更好呢？对于这些问题，我建议你去阅读相应的会议，期刊，杂志，硕士、博士毕业论文（毕竟硕士、博士研究生本就该从事“研究”工作），看看别人写的文章，自然就知道了。&lt;/p&gt;&#xA;&lt;p&gt;对于特征选择，OpenCV并没有提供特定的函数来进行衡量。而特征的分类能力的高低评价，有很多种分析方法，有兴趣的朋友，可以阅读&amp;quot;《机器学习》Tom. Mitchell(著),曾华军(译)，机械工业出版社&amp;quot;这本书；&lt;/p&gt;&#xA;&lt;p&gt;对于分类器部分，OpenCV提供了SVM,CART,boost,bayes,bdt,ANN,这几种常用的算法。而这些基本已经覆盖了常用的分类器。所以，你需要做的，就是知道怎么调用其接口，各种分类器的优点和缺点（该部分，建议阅读“机器学习”这本书）。&lt;/p&gt;&#xA;&lt;p&gt;通过以上的分析，你或许已经发现，OpenCV不过是一个工具而已。或者，你可以将它理解为幼儿园小朋友过家家玩的积木，而OpenCV中的函数，则可以理解为一个一个的积木块，利用所有或者部分积木块，你可以快速的搭建起来具体的计算机视觉方面的应用（比如，字符识别，车牌识别，遗留物检测）。想必你也已经发现，在利用OpenCV这个积木来搭建具体的计算机视觉应用的时候，真正核心的，应该是这些积木块，如果你明白了积木块的工作原理，那么，是不是就可以不用这些积木块了呢？完全正确！不过，一般部分情况下，我们不需要这么做，因为，OpenCV已经帮你做好了一些工作（已经帮你做好了一些积木块，直接拿来用就是了）。但是，诸如前面提到的特征提取模块，很多情况下，OpenCV就无能为力了。这个时候，你就需要翻阅计算机视觉、模式识别、机器学习领域顶级会议、期刊、杂志上面发表的文章了。然后，根据这些文章中阐述的原理和方法，来编程实现你要的东西。实际上，也就等于搭建一个属于你私有的积木块。其实，OpenCV中的每一个API函数，也就是这么来的。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
